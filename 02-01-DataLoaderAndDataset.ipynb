{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## 02-01 DataLoader and Dataset"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":"'1.3.0'"},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":"import os\nimport random\nimport shutil\nfrom pathlib import Path\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\n\nrandom.seed(1)\ntorch.manual_seed(0)\ntorch.__version__"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### 1.将人民币原始数据划分为训练集、验证集、测试集"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"设置需要处理的各个文件路径"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"raw_path: /media/bnu/file/datasets/pytorch-tutorials/rmb_data/raw_data\ntrain_path: /media/bnu/file/datasets/pytorch-tutorials/rmb_data/split_data/train\nvalid_path: /media/bnu/file/datasets/pytorch-tutorials/rmb_data/split_data/valid\ntest_path: /media/bnu/file/datasets/pytorch-tutorials/rmb_data/split_data/test\n"}],"source":"rmb_data_path = Path('/media/bnu/file/datasets/pytorch-tutorials/rmb_data')\nraw_path = rmb_data_path / 'raw_data'\nsplit_path = rmb_data_path / 'split_data'\ntrain_path = split_path / 'train'\nvalid_path = split_path / 'valid'\ntest_path = split_path / 'test'\n\nprint('raw_path:', raw_path)\nprint('train_path:', train_path)\nprint('valid_path:', valid_path)\nprint('test_path:', test_path)\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"设定训练集、验证集、测试集比例并进行划分"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Class: 100, Train: 80, Valid: 10, Test: 10\nClass: 1, Train: 80, Valid: 10, Test: 10\n"}],"source":"train_pct, valid_pct, test_pct = 0.8, 0.1, 0.1\n\nfor root, dirs, files in os.walk(raw_path):\n    for sub_dir in dirs:\n        # 获取目录中所有图片名称，并进行排序\n        image_file_list = os.listdir(raw_path / sub_dir)\n        image_file_list = list(filter(lambda x: x.endswith('.jpg'), image_file_list))\n        random.shuffle(image_file_list)\n        \n        # 计算划分区间\n        image_count = len(image_file_list)\n        train_point = int(image_count * train_pct)\n        valid_point = int(image_count * (train_pct + valid_pct))\n\n        # 根据数据集划分将图片保存到对应目录\n        for i in range(image_count):\n            if i < train_point:\n                out_dir = train_path / sub_dir\n            elif i < valid_point:\n                out_dir = valid_path / sub_dir\n            else:\n                out_dir = test_path / sub_dir\n            \n            if not os.path.exists(out_dir):\n                os.makedirs(out_dir)\n\n            target_path = out_dir / image_file_list[i]\n            source_path = raw_path / sub_dir / image_file_list[i]\n            shutil.copy(source_path, target_path)\n        \n        print(f'Class: {sub_dir}, Train: {train_point}, Valid: {valid_point - train_point}, Test: {image_count - valid_point}')\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### 2.定义数据集的Dataset"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":"(tensor([[[0.7647, 0.7373, 0.7216,  ..., 0.7608, 0.7765, 0.8157],\n          [0.7451, 0.7176, 0.7137,  ..., 0.7255, 0.7490, 0.8000],\n          [0.7255, 0.7725, 0.8275,  ..., 0.7333, 0.7529, 0.7922],\n          ...,\n          [0.8392, 0.8745, 0.9137,  ..., 0.8784, 0.8902, 0.9059],\n          [0.8824, 0.8824, 0.8824,  ..., 0.9137, 0.9216, 0.9333],\n          [0.8980, 0.8941, 0.8941,  ..., 0.9333, 0.9373, 0.9412]],\n \n         [[0.7804, 0.7529, 0.7373,  ..., 0.7843, 0.8000, 0.8314],\n          [0.7490, 0.7255, 0.7294,  ..., 0.7451, 0.7647, 0.8118],\n          [0.7255, 0.7686, 0.8235,  ..., 0.7490, 0.7647, 0.7961],\n          ...,\n          [0.8471, 0.8706, 0.9137,  ..., 0.8980, 0.9020, 0.9176],\n          [0.8941, 0.8941, 0.8941,  ..., 0.9294, 0.9373, 0.9451],\n          [0.9059, 0.9059, 0.9059,  ..., 0.9451, 0.9490, 0.9529]],\n \n         [[0.7961, 0.7686, 0.7529,  ..., 0.8078, 0.8196, 0.8510],\n          [0.7765, 0.7412, 0.7255,  ..., 0.8000, 0.8157, 0.8510],\n          [0.7922, 0.8078, 0.8078,  ..., 0.8549, 0.8627, 0.8706],\n          ...,\n          [0.8745, 0.8902, 0.9059,  ..., 0.9412, 0.9412, 0.9490],\n          [0.8980, 0.8941, 0.8902,  ..., 0.9373, 0.9412, 0.9451],\n          [0.9098, 0.9020, 0.9020,  ..., 0.9412, 0.9451, 0.9490]]]), 1)"},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":"class RMBDataset(Dataset):\n    \n    def __init__(self, image_path, transform=None):\n        self.label_dict = {'1': 0, '100': 1}\n        self.transform = transform\n\n        self.image_data = []\n        for root, dirs, files in os.walk(image_path):\n            for sub_dir in dirs:\n                # 获取目录下所有图片列表\n                image_file_list = os.listdir(image_path / sub_dir)\n                image_file_list = list(filter(lambda x: x.endswith('.jpg'), image_file_list))\n\n                # 保存每个图片的路径和标签\n                for i in range(len(image_file_list)):\n                    image_name = image_file_list[i]\n                    file_path = image_path / sub_dir / image_name\n                    label = self.label_dict[sub_dir]\n                    self.image_data.append((file_path, label))\n\n    def __getitem__(self, index):\n        file_path, label = self.image_data[index]\n        image = Image.open(file_path).convert('RGB')  # 数据范围0-255\n        \n        # 对图片进行transform\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image, label\n\n    def __len__(self):\n        return len(self.image_data)\n\n\ntemp_transform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor()\n])\ntemp_dataset = RMBDataset(train_path, transform=temp_transform)\ntemp_dataset[0]"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### 3.定义数据集的DataLoader"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Batch Shape:  torch.Size([16, 3, 32, 32]) Labels Shape: torch.Size([16])\n"}],"source":"# 标准化三通道的均值和标准差\nnorm_mean = [0.485, 0.456, 0.406]\nnorm_std = [0.229, 0.224, 0.225]\n\n# 定义训练集和验证集的transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(norm_mean, norm_std)\n])\nvalid_transform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize(norm_mean, norm_std)\n])\n\n# 构建Dataset实例\ntrain_dataset = RMBDataset(image_path=train_path, transform=train_transform)\nvalid_dataset = RMBDataset(image_path=valid_path, transform=valid_transform)\n\n# 构建DataLoader\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\nvalid_loader = DataLoader(dataset =valid_dataset, batch_size=16)\n\nfor i, (inputs, labels) in enumerate(train_loader):\n    print('Batch Shape: ', inputs.shape, 'Labels Shape:', labels.shape)\n    break"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}