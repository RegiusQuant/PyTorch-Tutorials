{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 05-03 Hook Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.Hook Method"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b246eecacde3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b246eecacde3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensor hook\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Tensor Register Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "gradient: tensor([5.]) tensor([2.]) None None None\na_grad[0]: tensor([2.])\n"
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "a_grad = list()\n",
    "\n",
    "def grad_hook(grad):\n",
    "    a_grad.append(grad)\n",
    "\n",
    "handle = a.register_hook(grad_hook)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print('gradient:', w.grad, x.grad, a.grad, b.grad, y.grad)\n",
    "print('a_grad[0]:', a_grad[0])\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "w.grad: tensor([30.])\n"
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "def grad_hook(grad):\n",
    "    grad *= 2\n",
    "    return grad * 3\n",
    "\n",
    "handle = w.register_hook(grad_hook)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print('w.grad:', w.grad)\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Module Register Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "forward_pre_hook input:(tensor([[[[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]]]),)\nbackward hook input: (None, tensor([[[[0.5000, 0.5000, 0.5000],\n          [0.5000, 0.5000, 0.5000],\n          [0.5000, 0.5000, 0.5000]]],\n\n\n        [[[0.5000, 0.5000, 0.5000],\n          [0.5000, 0.5000, 0.5000],\n          [0.5000, 0.5000, 0.5000]]]]), tensor([0.5000, 0.5000]))\nbackward hook output: (tensor([[[[0.5000, 0.0000],\n          [0.0000, 0.0000]],\n\n         [[0.5000, 0.0000],\n          [0.0000, 0.0000]]]]),)\noutput shape: torch.Size([1, 2, 1, 1])\noutput value: tensor([[[[ 9.]],\n\n         [[18.]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n\nfeature maps shape: torch.Size([1, 2, 2, 2])\noutput value: tensor([[[[ 9.,  9.],\n          [ 9.,  9.]],\n\n         [[18., 18.],\n          [18., 18.]]]], grad_fn=<MkldnnConvolutionBackward>)\n\ninput shape: torch.Size([1, 1, 4, 4])\ninput value: (tensor([[[[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]]]),)\n"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        return x\n",
    "\n",
    "def forward_hook(module, data_input, data_output):\n",
    "    fmap_block.append(data_output)\n",
    "    input_block.append(data_input)\n",
    "\n",
    "def forward_pre_hook(module, data_input):\n",
    "    print('forward_pre_hook input:{}'.format(data_input))\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    print('backward hook input: {}'.format(grad_input))\n",
    "    print('backward hook output: {}'.format(grad_output))\n",
    "\n",
    "net = Net()\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.data.detach().zero_()\n",
    "\n",
    "fmap_block, input_block = [], []\n",
    "net.conv1.register_forward_hook(forward_hook)\n",
    "net.conv1.register_forward_pre_hook(forward_pre_hook)\n",
    "net.conv1.register_backward_hook(backward_hook)\n",
    "\n",
    "fake_img = torch.ones(1, 1, 4, 4)\n",
    "output = net(fake_img)\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "target = torch.randn_like(output)\n",
    "loss = loss_func(target, output)\n",
    "loss.backward()\n",
    "\n",
    "print(\"output shape: {}\\noutput value: {}\\n\".format(output.shape, output))\n",
    "print(\"feature maps shape: {}\\noutput value: {}\\n\".format(fmap_block[0].shape, fmap_block[0]))\n",
    "print(\"input shape: {}\\ninput value: {}\".format(input_block[0][0].shape, input_block[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.FMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.49139968, 0.48215827, 0.44653124],\n",
    "        [0.24703233, 0.24348505, 0.26158768]\n",
    "    )\n",
    "])\n",
    "\n",
    "image_path = Path('./image/lena.png')\n",
    "img_pil = Image.open(image_path).convert('RGB')\n",
    "img_tensor = image_transforms(img_pil)\n",
    "img_tensor.unsqueeze_(0)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "fmap_dict = {}\n",
    "for name, sub_module in alexnet.named_modules():\n",
    "    if isinstance(sub_module, nn.Conv2d):\n",
    "        key_name = str(sub_module.weight.shape)\n",
    "        fmap_dict.setdefault(key_name, list())\n",
    "\n",
    "        n1, n2 = name.split('.')\n",
    "\n",
    "        def hook_func(m, i, o):\n",
    "            key_name = str(m.weight.shape)\n",
    "            fmap_dict[key_name].append(o)\n",
    "\n",
    "        alexnet._modules[n1]._modules[n2].register_forward_hook(hook_func)\n",
    "\n",
    "output = alexnet(img_tensor)\n",
    "\n",
    "writer = SummaryWriter(comment='test_your_comment', filename_suffix=\"_test_your_filename_suffix\")\n",
    "for layer_name, fmap_list in fmap_dict.items():\n",
    "    fmap = fmap_list[0]\n",
    "    fmap.transpose_(0, 1)\n",
    "\n",
    "    nrow = int(np.sqrt(fmap.shape[0]))\n",
    "    fmap_grid = vutils.make_grid(fmap, normalize=True, scale_each=True, nrow=nrow)\n",
    "    writer.add_image('feature map in {}'.format(layer_name), fmap_grid, global_step=322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}