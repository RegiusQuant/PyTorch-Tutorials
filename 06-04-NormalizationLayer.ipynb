{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 06-04 Normalization Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'1.3.1'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Layer Normalization\ntorch.Size([6, 3, 4])\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[2., 2., 2., 2.],\n         [2., 2., 2., 2.],\n         [2., 2., 2., 2.]],\n\n        [[3., 3., 3., 3.],\n         [3., 3., 3., 3.],\n         [3., 3., 3., 3.]],\n\n        [[4., 4., 4., 4.],\n         [4., 4., 4., 4.],\n         [4., 4., 4., 4.]],\n\n        [[5., 5., 5., 5.],\n         [5., 5., 5., 5.],\n         [5., 5., 5., 5.]],\n\n        [[6., 6., 6., 6.],\n         [6., 6., 6., 6.],\n         [6., 6., 6., 6.]]])\ntensor([[[-1.4638, -1.4638, -1.4638, -1.4638],\n         [-1.4638, -1.4638, -1.4638, -1.4638],\n         [-1.4638, -1.4638, -1.4638, -1.4638]],\n\n        [[-0.8783, -0.8783, -0.8783, -0.8783],\n         [-0.8783, -0.8783, -0.8783, -0.8783],\n         [-0.8783, -0.8783, -0.8783, -0.8783]],\n\n        [[-0.2928, -0.2928, -0.2928, -0.2928],\n         [-0.2928, -0.2928, -0.2928, -0.2928],\n         [-0.2928, -0.2928, -0.2928, -0.2928]],\n\n        [[ 0.2928,  0.2928,  0.2928,  0.2928],\n         [ 0.2928,  0.2928,  0.2928,  0.2928],\n         [ 0.2928,  0.2928,  0.2928,  0.2928]],\n\n        [[ 0.8783,  0.8783,  0.8783,  0.8783],\n         [ 0.8783,  0.8783,  0.8783,  0.8783],\n         [ 0.8783,  0.8783,  0.8783,  0.8783]],\n\n        [[ 1.4638,  1.4638,  1.4638,  1.4638],\n         [ 1.4638,  1.4638,  1.4638,  1.4638],\n         [ 1.4638,  1.4638,  1.4638,  1.4638]]], grad_fn=<SelectBackward>)\n"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "num_features = 6\n",
    "\n",
    "feature_shape = (3, 4)\n",
    "\n",
    "feature_map = torch.ones(feature_shape)\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)\n",
    "\n",
    "norm = nn.LayerNorm([6, 3, 4])\n",
    "outputs = norm(feature_maps_bs)\n",
    "\n",
    "print('Layer Normalization')\n",
    "print(norm.weight.shape)\n",
    "print(feature_maps_bs[0, ...])\n",
    "print(outputs[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.InstanceNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Instance Normalization\ninput: \ntensor([[[[1., 1.],\n          [1., 1.]],\n\n         [[2., 2.],\n          [2., 2.]],\n\n         [[3., 3.],\n          [3., 3.]]],\n\n\n        [[[1., 1.],\n          [1., 1.]],\n\n         [[2., 2.],\n          [2., 2.]],\n\n         [[3., 3.],\n          [3., 3.]]],\n\n\n        [[[1., 1.],\n          [1., 1.]],\n\n         [[2., 2.],\n          [2., 2.]],\n\n         [[3., 3.],\n          [3., 3.]]]])\n shape: torch.Size([3, 3, 2, 2])\ntensor([[[[0., 0.],\n          [0., 0.]],\n\n         [[0., 0.],\n          [0., 0.]],\n\n         [[0., 0.],\n          [0., 0.]]],\n\n\n        [[[0., 0.],\n          [0., 0.]],\n\n         [[0., 0.],\n          [0., 0.]],\n\n         [[0., 0.],\n          [0., 0.]]],\n\n\n        [[[0., 0.],\n          [0., 0.]],\n\n         [[0., 0.],\n          [0., 0.]],\n\n         [[0., 0.],\n          [0., 0.]]]])\n"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "num_features = 3\n",
    "momentum = 0.3\n",
    "\n",
    "feature_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(feature_shape)\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)\n",
    "\n",
    "print('Instance Normalization')\n",
    "print('input: \\n{}\\n shape: {}'.format(feature_maps_bs, feature_maps_bs.shape))\n",
    "\n",
    "norm = nn.InstanceNorm2d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "outputs = norm(feature_maps_bs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.GroupNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Group Normalization\ntorch.Size([6])\ntensor([[[-1.0000, -1.0000],\n         [-1.0000, -1.0000]],\n\n        [[ 1.0000,  1.0000],\n         [ 1.0000,  1.0000]],\n\n        [[-1.0000, -1.0000],\n         [-1.0000, -1.0000]],\n\n        [[ 1.0000,  1.0000],\n         [ 1.0000,  1.0000]],\n\n        [[-1.0000, -1.0000],\n         [-1.0000, -1.0000]],\n\n        [[ 1.0000,  1.0000],\n         [ 1.0000,  1.0000]]], grad_fn=<SelectBackward>)\n"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_features = 6\n",
    "num_groups = 3\n",
    "\n",
    "feature_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(feature_shape)\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)\n",
    "\n",
    "norm = nn.GroupNorm(num_groups, num_features)\n",
    "outputs = norm(feature_maps_bs)\n",
    "\n",
    "print('Group Normalization')\n",
    "print(norm.weight.shape)\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}